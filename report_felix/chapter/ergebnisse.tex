\chapter{Ergebnisse der Hyperparameter-Optimierung und des Trainings}
\section{Hyperparameter-Optimierung von \MiniDog}

In \autoref{fig:hyper-param} ist das Ergebnis der Hyperparameter-Optimierung von \MiniDog
dargestellt. Die optimalen Hyperparameter sind eine \texttt{Batch Size} von 2,
eine Stärke von 0.001 der \texttt{L2-Regularisierung} und die Verwendung
der Farbinformationen.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{pics/ergebnisse/hyper_raum.pdf}
  \caption{Darstellung der Ergebnisse der Hyperparameter-Optimierung
  von \MiniDog. Die beste Kombination ist als Stern dargestellt und wurde auch
  für das Training verwendet.}
  \label{fig:hyper-param}
\end{figure}

Allgemein wird ersichtlich, dass in den meisten Fällen die Verwendung von Farbinformationen
zu einer höheren Validation Accuracy führt. Also kann eine der Fragen, ob die Verwendung
von Farbinformationen einen Vorteil in der Klassifikation bringt, mit Ja beantwortet werden.

\section{Verschiedene Bildgrößen beim  Training von \PreDog und \PreBig}

Wie bereits in \autoref{sec:größe-bilder} beschrieben, wurde für die beiden
Neuronalen Netze, die ein vortrainiertes Netz nutzen, alle Bilder 125x138
geresized. Dies erreichte eine Validation Accuracy von ungefähr \SI{60}{\percent}.
Falls die Bilder aber auf 224x224 geresized werden, dann steigt die Accuracy
auf ungefähr \SI{95}{\percent}. Da im kleinen Datensatz nur maximal 74 Bilder
kleiner sind als 224x224, die Validation Accuracy aber deutlich besser ist, wird diese Methode zum Training verwendet.
Loss und Accuracy Kurven sind im Anhang zu finden.

\section{\PreBig}

In \autoref{fig:loss-acc-prebig} sind die Loss und Accuracy Kurven für \PreBig
zu sehen. Ungefähr ab Epoche 14 ist leichtes Overtraining zu erkennen. Hier
wäre eine Anpassung der \texttt{dropout-rate} und/oder der Stärke der \texttt{L2-Regularisierung}
Mögliche Stellschrauben, um das Overtraining zu beseitigen, möglicherweise im Zuge
einer umfassenden Hyperparameter-Optimierung.

\begin{figure}
  \centering
  \includegraphics[scale=0.8]{pics/ergebnisse/PreBigDogNN/history_epoch.pdf}
  \caption{Loss und Accuracy Kurven für \PreBig.}
  \label{fig:loss-acc-prebig}
\end{figure}

Die Confusion-Matrix zeigt eine deutliche Diagonale, was als gut zu bewerten ist.
Allerdings werden einzelne Klassen noch häufig falsch klassifiziert, zum Beispiel
ist ein vom Netz als American Staffordshire Terrier klassifizierter Hund zu ungefähr
\SI{80}{\percent} ein Staffordshire Bullterrier. Die Ähnlichkeit der beiden Rassen
steckt schon im Namen und wird bei genauerer Betrachtung der Bilder beider Klassen
deutlich. Alles in allem funktioniert die Klassifikation gut, einzelne Klassen
wie z.\.B. der African Hunting Dog werden (fast) immer richtig klassifiziert.

\begin{figure}
  \centering
  \includegraphics[scale=0.8]{pics/ergebnisse/PreBigDogNN/confusion_matrix.pdf}
  \caption{Confusion Matrix für \PreBig.}
  \label{fig:confusion-prebig}
\end{figure}

\section{\MiniDog}

In \autoref{fig:loss-acc-minidog} sind die Loss und Accuracy Kurven für \MiniDog
trainiert auf 5 Klassen zu sehen. Auch hier ist ab Periode 25 leichtes
Overtraining zu erkennen, welches mit stärkerer \texttt{L2-Regularisierung} oder
früherem Abbruch beseitigt werden könnte.

\begin{figure}
  \centering
  \includegraphics[scale=0.8]{pics/ergebnisse/MiniDogNN/history.pdf}
  \caption{Loss und Accuracy Kurven für \MiniDog.}
  \label{fig:loss-acc-minidog}
\end{figure}

\autoref{fig:confusion-mini} zeigt die Confusion-Matrix des Trainings aus
\autoref{fig:loss-acc-minidog}. Es zeigt sich, dass der African Hunting Dog im
Vergleich zu den anderen Klassen sehr gut, am schlechtesten ist der Schipperke
zu klassifizieren. Dies zeigt sich auch in \autoref{fig:visualize-pred}. Dort
wurde der Schipperke am wahrscheinlichsten als African Hunting Dog
klassifiziert, was sich auch in der Confusion-Matrix zeigt. Bis auf den African
Hunting Dog in \autoref{fig:visualize-pred} entsprechen die wahrscheinlichsten
Predictions nicht den True Labeln. Hier ist also noch Verbesserungspotential,
z.\,B. durch eine umfassende Hyperparameter-Optimierung.

\begin{figure}
  \centering
  \includegraphics[scale=0.8]{pics/ergebnisse/MiniDogNN/confusion_matrix}
  \caption{Confusion-Matrix für das Training von MiniDogNN.}
  \label{fig:confusion-mini}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.8]{pics/ergebnisse/MiniDogNN/visualize_predictions.pdf}
  \caption{Auswahl von sechs Bilder aus dem Testdatensatz für \MiniDog mit den
  jeweilig wahrscheinlichsten Predictions.}
  \label{fig:visualize-pred}
\end{figure}

In \autoref{fig:confusion-mini-120} ist die Confusion-Matrix von \MiniDog
für 120 Klassen dargestellt ist. Es wird sofort ersichtlich, dass die Klassifikation
nicht gut funktioniert hat, da alle Bilder einer einzelnen Klasse zugeordnet werden.
Damit wird auch klar, dass nicht mit dem gleichen Netz 5 und 120 Klassen gut klassifiziert
werden können.

\begin{figure}
  \centering
  \includegraphics{pics/ergebnisse/MiniDogNN/confusion_matrix_mini120.pdf}
  \caption{Confusion Matrix für \MiniDog, trainiert auf 120 Klassen.}
  \label{fig:confusion-mini-120}
\end{figure}
